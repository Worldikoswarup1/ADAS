{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-_ni5zFByGw",
        "outputId": "0f78996a-7b5b-4f41-ee89-c7fb62d53d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.85)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics gtts opencv-python numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from gtts import gTTS\n",
        "from ultralytics import YOLO\n"
      ],
      "metadata": {
        "id": "JqXx9QRwCPDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained YOLOv10 model\n",
        "model = YOLO(\"yolov10s.pt\")  # Adjust model size if needed\n"
      ],
      "metadata": {
        "id": "9eVu71GrCSis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRQ0qQxSCVg0",
        "outputId": "11506b8d-e096-4d41-a87f-3564fc91c3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Install Dependencies ===\n",
        "!pip install ultralytics gtts opencv-python numpy moviepy deep_sort_realtime\n",
        "\n",
        "# === STEP 2: Mount Google Drive ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === STEP 3: Import Required Libraries ===\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip, AudioClip\n",
        "\n",
        "# Clear existing alert audio files\n",
        "import os\n",
        "\n",
        "# Path to the directory where mp3 files are stored\n",
        "directory_path = '/content/'\n",
        "\n",
        "# Loop through all files in the directory and delete the .mp3 files\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mp3\"):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        os.remove(file_path)\n",
        "        print(f\"Deleted: {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# === STEP 4: Global Variables and Constants ===\n",
        "alert_events = []         # To record alert events: list of (timestamp, alert_filename)\n",
        "free_lane_counters = {}   # For free lane detection (lane index -> consecutive free-frame count)\n",
        "\n",
        "FREE_LANE_MIN_AREA = 15000    # If a vehicle's bbox area >= this, lane is not considered free\n",
        "FREE_SPEED_THRESHOLD = 0.05    # If area increases >5% (per frame), the vehicle is approaching\n",
        "AREA_INCREASE_THRESHOLD = 0.2  # 20% increase for overtaking detection\n",
        "SMALL_VEHICLE_AREA_THRESHOLD = 20000  # Threshold to decide lateral boundaries based on vehicle size\n",
        "\n",
        "# === STEP 5: Load YOLOv10 Model ===\n",
        "model = YOLO(\"yolov10s\")  # Pretrained YOLOv10 small\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# === STEP 6: Define Lane Detection Functions ===\n",
        "def detect_lanes(frame):\n",
        "    \"\"\"Detect lane lines using Canny edge detection and HoughLinesP.\n",
        "       Returns a sorted list of x-coordinates representing lane centers.\"\"\"\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros_like(edges)\n",
        "    polygon = np.array([[ (0, height), (width, height), (width, int(height * 0.6)), (0, int(height * 0.6)) ]], np.int32)\n",
        "    cv2.fillPoly(mask, polygon, 255)\n",
        "    roi_edges = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "    lines = cv2.HoughLinesP(roi_edges, 1, np.pi/180, threshold=50, minLineLength=50, maxLineGap=50)\n",
        "    lane_centers = []\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, _, x2, _ = line[0]\n",
        "            lane_centers.append((x1 + x2) // 2)\n",
        "    return sorted(list(set(lane_centers)))\n",
        "\n",
        "def divide_lane_regions(lane_centers, frame_width):\n",
        "    \"\"\"Divide the frame width into lane regions. If lanes are not clearly detected, default to 3 equal regions.\"\"\"\n",
        "    if len(lane_centers) < 2:\n",
        "        region_width = frame_width // 3\n",
        "        return [(0, region_width), (region_width, 2*region_width), (2*region_width, frame_width)]\n",
        "    else:\n",
        "        region_width = frame_width // 3\n",
        "        # For simplicity, always use 3 equal regions: left, ego, right.\n",
        "        return [(0, region_width), (region_width, 2*region_width), (2*region_width, frame_width)]\n",
        "\n",
        "def get_ego_lane(lane_regions):\n",
        "    \"\"\"Assume the ego lane is the middle region if three lanes are defined.\"\"\"\n",
        "    return 1 if len(lane_regions) >= 3 else 0\n",
        "\n",
        "def assign_to_lane(x_center, lane_regions):\n",
        "    \"\"\"Return the lane index where x_center falls based on lane regions.\"\"\"\n",
        "    for idx, (start, end) in enumerate(lane_regions):\n",
        "        if start <= x_center <= end:\n",
        "            return idx\n",
        "    return -1\n",
        "\n",
        "# === STEP 7: Initialize DeepSORT Tracker and Tracking Info ===\n",
        "tracker = DeepSort(max_age=30)\n",
        "tracked_info = {}  # To store previous frame info: {track_id: {'area': float, 'lane': int, 'x_center': int}}\n",
        "\n",
        "# === STEP 8: Define Audio Alert Function ===\n",
        "def play_audio_alert(message, current_time):\n",
        "    \"\"\"\n",
        "    Save TTS audio alert with a unique filename based on the timestamp,\n",
        "    record the event, and play the alert.\n",
        "    \"\"\"\n",
        "    alert_filename = f\"alert_{current_time:.1f}.mp3\"\n",
        "    # Save the alert only if it doesn't already exist (to avoid re-generation in merging)\n",
        "    if not os.path.exists(alert_filename):\n",
        "        tts = gTTS(text=message, lang='en')\n",
        "        tts.save(alert_filename)\n",
        "    # Record the event for later merging\n",
        "    alert_events.append((current_time, alert_filename))\n",
        "    # Play the alert immediately\n",
        "    display(Audio(alert_filename, autoplay=True))\n",
        "\n",
        "# === STEP 9: Process Video Function (Merging Free Lane & Overtaking Logic) ===\n",
        "def process_video(input_path, output_path):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    global tracked_info, free_lane_counters\n",
        "    frame_idx = 0\n",
        "\n",
        "    # Dictionaries to store the filled box information with detection timestamp\n",
        "    overtaking_boxes = {}  # key: track_id, value: (detection_time, (x1, y1, x2, y2))\n",
        "    free_lane_fills = {}   # key: lane index, value: (detection_time, (start, y_top, end, y_bottom))\n",
        "    OCCUPY_DURATION = 1.0  # Duration in seconds to keep the fill\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_idx += 1\n",
        "        current_time = frame_idx / fps\n",
        "        print(f\"Processing frame {frame_idx} at {current_time:.2f} sec\")\n",
        "\n",
        "        # Lane Detection\n",
        "        lane_centers = detect_lanes(frame)\n",
        "        lane_regions = divide_lane_regions(lane_centers, width)\n",
        "        ego_lane = get_ego_lane(lane_regions)\n",
        "\n",
        "        # Visualize lane regions (outline only)\n",
        "        for idx, (start, end) in enumerate(lane_regions):\n",
        "            color = (0, 255, 0) if idx != ego_lane else (255, 255, 0)\n",
        "            cv2.rectangle(frame, (start, int(height*0.6)), (end, height), color, 2)\n",
        "            cv2.putText(frame, f\"Lane {idx}\", (start+5, int(height*0.6)-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "        # Vehicle Detection via YOLOv10\n",
        "        results = model(frame)\n",
        "        detections = []\n",
        "        for r in results:\n",
        "            for box in r.boxes.data:\n",
        "                x1, y1, x2, y2, conf, cls = box.tolist()\n",
        "                if conf < 0.4:\n",
        "                    continue\n",
        "                detections.append(([x1, y1, x2, y2], conf, cls))\n",
        "\n",
        "        # Update DeepSORT Tracker\n",
        "        tracks = tracker.update_tracks(detections, frame=frame)\n",
        "        current_info = {}\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            ltwh = track.to_ltwh()  # (left, top, width, height)\n",
        "            x1, y1, w, h = ltwh\n",
        "            x2, y2 = x1 + w, y1 + h\n",
        "            x_center = int(x1 + w/2)\n",
        "            area = w * h\n",
        "            lane_assignment = assign_to_lane(x_center, lane_regions)\n",
        "\n",
        "            # Draw a normal (blue) bounding box for display (for debugging or info)\n",
        "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, f\"ID:{track_id} L:{lane_assignment}\", (int(x1), int(y1)-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "            current_info[track_id] = {'area': area, 'lane': lane_assignment, 'x_center': x_center}\n",
        "\n",
        "            # Overtaking Detection: when a vehicle in the ego lane moves to another lane with a significant area increase\n",
        "            if track_id in tracked_info:\n",
        "                prev = tracked_info[track_id]\n",
        "                if prev['area'] > 0:\n",
        "                    area_ratio = (area - prev['area']) / prev['area']\n",
        "                else:\n",
        "                    area_ratio = 0\n",
        "                if prev['lane'] == ego_lane and lane_assignment != ego_lane and area_ratio > AREA_INCREASE_THRESHOLD:\n",
        "                    # Set dynamic lateral thresholds based on vehicle size\n",
        "                    if area < SMALL_VEHICLE_AREA_THRESHOLD:\n",
        "                        left_threshold = 0.35 * width\n",
        "                        right_threshold = 0.65 * width\n",
        "                    else:\n",
        "                        left_threshold = 0.30 * width\n",
        "                        right_threshold = 0.70 * width\n",
        "                    if lane_assignment < ego_lane and x_center < left_threshold:\n",
        "                        alert = \"right lane busy\"\n",
        "                        cv2.putText(frame, alert, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "                        play_audio_alert(alert, current_time)\n",
        "                        # Record detection with bounding box coordinates\n",
        "                        overtaking_boxes[track_id] = (current_time, (int(x1), int(y1), int(x2), int(y2)))\n",
        "                    elif lane_assignment > ego_lane and x_center > right_threshold:\n",
        "                        alert = \"left lane busy\"\n",
        "                        cv2.putText(frame, alert, (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "                        play_audio_alert(alert, current_time)\n",
        "                        overtaking_boxes[track_id] = (current_time, (int(x1), int(y1), int(x2), int(y2)))\n",
        "\n",
        "        # Draw red filled rectangles for overtaking vehicles if within OCCUPY_DURATION\n",
        "        for tid, (det_time, bbox) in list(overtaking_boxes.items()):\n",
        "            if current_time - det_time <= OCCUPY_DURATION:\n",
        "                x1_box, y1_box, x2_box, y2_box = bbox\n",
        "                cv2.rectangle(frame, (x1_box, y1_box), (x2_box, y2_box), (0, 0, 255), -1)  # Red filled\n",
        "            else:\n",
        "                # Remove expired entries\n",
        "                del overtaking_boxes[tid]\n",
        "\n",
        "        # Free Lane Detection with 3-second rule and safety check:\n",
        "        for idx, region in enumerate(lane_regions):\n",
        "            lane_tracks = {tid: info for tid, info in current_info.items() if info['lane'] == idx}\n",
        "            lane_free = True\n",
        "            for tid, info in lane_tracks.items():\n",
        "                if info['area'] >= FREE_LANE_MIN_AREA:\n",
        "                    lane_free = False\n",
        "                    break\n",
        "                if tid in tracked_info:\n",
        "                    prev_area = tracked_info[tid]['area']\n",
        "                    if prev_area > 0:\n",
        "                        ratio = (info['area'] - prev_area) / prev_area\n",
        "                        if ratio > FREE_SPEED_THRESHOLD:\n",
        "                            lane_free = False\n",
        "                            break\n",
        "            if lane_free:\n",
        "                free_lane_counters[idx] = free_lane_counters.get(idx, 0) + 1\n",
        "            else:\n",
        "                free_lane_counters[idx] = 0\n",
        "\n",
        "            if free_lane_counters.get(idx, 0) >= fps * 3:\n",
        "                if idx < ego_lane:\n",
        "                    alert = \"right lane clear\"\n",
        "                elif idx > ego_lane:\n",
        "                    alert = \"left lane clear\"\n",
        "                else:\n",
        "                    alert = \"both lane clear\"\n",
        "                cv2.putText(frame, alert, (50, 100 + idx*30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
        "                play_audio_alert(alert, current_time)\n",
        "                # Record free lane fill region (from y = int(height*0.6) to height)\n",
        "                start, end = lane_regions[idx]\n",
        "                free_lane_fills[idx] = (current_time, (start, int(height*0.6), end, height))\n",
        "                free_lane_counters[idx] = 0\n",
        "\n",
        "        # Draw green filled rectangles for free lanes if within OCCUPY_DURATION\n",
        "        for idx, (det_time, region_coords) in list(free_lane_fills.items()):\n",
        "            if current_time - det_time <= OCCUPY_DURATION:\n",
        "                start, y_top, end, y_bottom = region_coords\n",
        "                cv2.rectangle(frame, (start, y_top), (end, y_bottom), (0, 255, 0), -1)  # Green filled\n",
        "            else:\n",
        "                del free_lane_fills[idx]\n",
        "\n",
        "        out.write(frame)\n",
        "        tracked_info = current_info.copy()\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Video processing complete!\")\n",
        "\n",
        "\n",
        "# === STEP 10: Run Video Processing ===\n",
        "# Update these paths as per your Drive structure\n",
        "input_video = \"/content/drive/My Drive/deepdrive/freenovrtk.mp4\"\n",
        "temp_output_video = \"/content/drive/My Drive/deepdrive/detected_output.avi\"\n",
        "process_video(input_video, temp_output_video)\n",
        "print(\"Processing complete! Video saved at:\", temp_output_video)\n",
        "\n",
        "# === STEP 11: Merge Audio with Video Using MoviePy ===\n",
        "video_clip = VideoFileClip(temp_output_video)\n",
        "duration = video_clip.duration\n",
        "def make_silence(t):\n",
        "    return 0\n",
        "silent_audio = AudioClip(make_silence, duration=duration, fps=44100)\n",
        "alert_clips = []\n",
        "for timestamp, alert_filename in alert_events:\n",
        "    if os.path.exists(alert_filename):\n",
        "        alert_audio = AudioFileClip(alert_filename)\n",
        "        alert_audio = alert_audio.set_start(timestamp)\n",
        "        alert_clips.append(alert_audio)\n",
        "if alert_clips:\n",
        "    composite_audio = CompositeAudioClip([silent_audio] + alert_clips)\n",
        "else:\n",
        "    composite_audio = silent_audio\n",
        "final_output = \"/content/drive/My Drive/deepdrive/final_output.mp4\"\n",
        "final_clip = video_clip.set_audio(composite_audio)\n",
        "final_clip.write_videofile(final_output, codec=\"libx264\", audio_codec=\"aac\")\n",
        "print(\"Final video with audio saved at:\", final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OM4eKjvZEr35",
        "outputId": "daa2e2e7-b8b5-4e6c-ea83-e036ed525201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.85)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: deep_sort_realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Deleted: /content/alert_8.8.mp3\n",
            "Deleted: /content/alert_3.0.mp3\n",
            "Using device: cuda\n",
            "Processing frame 1 at 0.05 sec\n",
            "\n",
            "0: 384x640 (no detections), 31.0ms\n",
            "Speed: 3.5ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 2 at 0.09 sec\n",
            "\n",
            "0: 384x640 (no detections), 30.0ms\n",
            "Speed: 4.4ms preprocess, 30.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 3 at 0.14 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 3.5ms preprocess, 17.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 4 at 0.18 sec\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 3.5ms preprocess, 19.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 5 at 0.23 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 6 at 0.27 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 3.4ms preprocess, 17.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 7 at 0.32 sec\n",
            "\n",
            "0: 384x640 (no detections), 27.9ms\n",
            "Speed: 3.6ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 8 at 0.36 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 3.5ms preprocess, 17.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 9 at 0.41 sec\n",
            "\n",
            "0: 384x640 (no detections), 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 10 at 0.45 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 3.6ms preprocess, 18.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 11 at 0.50 sec\n",
            "\n",
            "0: 384x640 (no detections), 21.5ms\n",
            "Speed: 3.4ms preprocess, 21.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 12 at 0.55 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 3.5ms preprocess, 17.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 13 at 0.59 sec\n",
            "\n",
            "0: 384x640 (no detections), 24.2ms\n",
            "Speed: 3.7ms preprocess, 24.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 14 at 0.64 sec\n",
            "\n",
            "0: 384x640 (no detections), 61.3ms\n",
            "Speed: 5.6ms preprocess, 61.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 15 at 0.68 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 3.7ms preprocess, 17.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 16 at 0.73 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 3.6ms preprocess, 18.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 17 at 0.77 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 3.6ms preprocess, 18.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 18 at 0.82 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 3.5ms preprocess, 17.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 19 at 0.86 sec\n",
            "\n",
            "0: 384x640 (no detections), 37.9ms\n",
            "Speed: 5.1ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 20 at 0.91 sec\n",
            "\n",
            "0: 384x640 (no detections), 42.9ms\n",
            "Speed: 3.5ms preprocess, 42.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 21 at 0.95 sec\n",
            "\n",
            "0: 384x640 (no detections), 29.2ms\n",
            "Speed: 3.5ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 22 at 1.00 sec\n",
            "\n",
            "0: 384x640 (no detections), 43.9ms\n",
            "Speed: 3.8ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 23 at 1.05 sec\n",
            "\n",
            "0: 384x640 (no detections), 60.7ms\n",
            "Speed: 3.7ms preprocess, 60.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 24 at 1.09 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 3.9ms preprocess, 18.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 25 at 1.14 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 3.8ms preprocess, 18.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 26 at 1.18 sec\n",
            "\n",
            "0: 384x640 1 fire hydrant, 46.3ms\n",
            "Speed: 3.6ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 27 at 1.23 sec\n",
            "\n",
            "0: 384x640 1 truck, 16.9ms\n",
            "Speed: 3.6ms preprocess, 16.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 28 at 1.27 sec\n",
            "\n",
            "0: 384x640 1 truck, 20.8ms\n",
            "Speed: 3.7ms preprocess, 20.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 29 at 1.32 sec\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 4.3ms preprocess, 20.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 30 at 1.36 sec\n",
            "\n",
            "0: 384x640 (no detections), 33.7ms\n",
            "Speed: 7.7ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 31 at 1.41 sec\n",
            "\n",
            "0: 384x640 (no detections), 38.5ms\n",
            "Speed: 4.7ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 32 at 1.45 sec\n",
            "\n",
            "0: 384x640 (no detections), 34.0ms\n",
            "Speed: 9.6ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 33 at 1.50 sec\n",
            "\n",
            "0: 384x640 (no detections), 21.2ms\n",
            "Speed: 4.1ms preprocess, 21.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 34 at 1.55 sec\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 4.7ms preprocess, 16.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 35 at 1.59 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 3.7ms preprocess, 17.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 36 at 1.64 sec\n",
            "\n",
            "0: 384x640 (no detections), 51.7ms\n",
            "Speed: 3.5ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 37 at 1.68 sec\n",
            "\n",
            "0: 384x640 (no detections), 20.8ms\n",
            "Speed: 3.6ms preprocess, 20.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 38 at 1.73 sec\n",
            "\n",
            "0: 384x640 (no detections), 49.6ms\n",
            "Speed: 3.5ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 39 at 1.77 sec\n",
            "\n",
            "0: 384x640 (no detections), 29.8ms\n",
            "Speed: 4.5ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 40 at 1.82 sec\n",
            "\n",
            "0: 384x640 (no detections), 39.2ms\n",
            "Speed: 3.4ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 41 at 1.86 sec\n",
            "\n",
            "0: 384x640 (no detections), 37.6ms\n",
            "Speed: 3.6ms preprocess, 37.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 42 at 1.91 sec\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 4.6ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 43 at 1.95 sec\n",
            "\n",
            "0: 384x640 (no detections), 19.5ms\n",
            "Speed: 4.3ms preprocess, 19.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 44 at 2.00 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 3.5ms preprocess, 18.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 45 at 2.05 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 46 at 2.09 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 47 at 2.14 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 48 at 2.18 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 49 at 2.23 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 50 at 2.27 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 51 at 2.32 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 52 at 2.36 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 53 at 2.41 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 54 at 2.45 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 55 at 2.50 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 56 at 2.55 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 57 at 2.59 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 58 at 2.64 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 59 at 2.68 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 13.9ms\n",
            "Speed: 3.9ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 60 at 2.73 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 61 at 2.77 sec\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 62 at 2.82 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 63 at 2.86 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 64 at 2.91 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 65 at 2.95 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 66 at 3.00 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing frame 67 at 3.05 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 68 at 3.09 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 69 at 3.14 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 70 at 3.18 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 71 at 3.23 sec\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 72 at 3.27 sec\n",
            "\n",
            "0: 384x640 (no detections), 20.7ms\n",
            "Speed: 3.8ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 73 at 3.32 sec\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 3.7ms preprocess, 21.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 74 at 3.36 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 3.5ms preprocess, 18.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 75 at 3.41 sec\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 3.4ms preprocess, 21.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 76 at 3.45 sec\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 3.7ms preprocess, 15.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 77 at 3.50 sec\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 78 at 3.55 sec\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 3.7ms preprocess, 14.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 79 at 3.59 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.0ms\n",
            "Speed: 3.5ms preprocess, 18.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 80 at 3.64 sec\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 3.8ms preprocess, 13.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 81 at 3.68 sec\n",
            "\n",
            "0: 384x640 (no detections), 19.7ms\n",
            "Speed: 3.3ms preprocess, 19.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 82 at 3.73 sec\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 6.1ms preprocess, 18.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 83 at 3.77 sec\n",
            "\n",
            "0: 384x640 (no detections), 19.6ms\n",
            "Speed: 3.3ms preprocess, 19.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 84 at 3.82 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 21.0ms\n",
            "Speed: 3.8ms preprocess, 21.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 85 at 3.86 sec\n",
            "\n",
            "0: 384x640 1 traffic light, 18.8ms\n",
            "Speed: 4.6ms preprocess, 18.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 86 at 3.91 sec\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 4.3ms preprocess, 16.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 87 at 3.95 sec\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 88 at 4.00 sec\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 89 at 4.05 sec\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 1 bus, 2 trucks, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 90 at 4.09 sec\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 2 buss, 1 truck, 13.4ms\n",
            "Speed: 3.7ms preprocess, 13.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 91 at 4.14 sec\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 2 buss, 13.4ms\n",
            "Speed: 3.5ms preprocess, 13.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 92 at 4.18 sec\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 buss, 1 truck, 16.2ms\n",
            "Speed: 5.2ms preprocess, 16.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 93 at 4.23 sec\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 buss, 1 truck, 14.2ms\n",
            "Speed: 4.7ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 94 at 4.27 sec\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 1 truck, 21.3ms\n",
            "Speed: 4.1ms preprocess, 21.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 95 at 4.32 sec\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 2 buss, 1 truck, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 96 at 4.36 sec\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 bus, 1 truck, 19.7ms\n",
            "Speed: 3.6ms preprocess, 19.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 97 at 4.41 sec\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 buss, 1 truck, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 98 at 4.45 sec\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 buss, 1 truck, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 99 at 4.50 sec\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 1 truck, 17.5ms\n",
            "Speed: 3.4ms preprocess, 17.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 100 at 4.55 sec\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 bus, 1 truck, 13.9ms\n",
            "Speed: 5.4ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 101 at 4.59 sec\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 bus, 1 truck, 17.1ms\n",
            "Speed: 3.8ms preprocess, 17.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 102 at 4.64 sec\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 bus, 1 truck, 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 103 at 4.68 sec\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 bus, 1 truck, 16.3ms\n",
            "Speed: 4.5ms preprocess, 16.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 104 at 4.73 sec\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 1 truck, 13.9ms\n",
            "Speed: 5.1ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 105 at 4.77 sec\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 bus, 1 truck, 14.0ms\n",
            "Speed: 4.9ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 106 at 4.82 sec\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 1 truck, 14.8ms\n",
            "Speed: 3.8ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 107 at 4.86 sec\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 1 truck, 18.6ms\n",
            "Speed: 3.6ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 108 at 4.91 sec\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 1 truck, 14.1ms\n",
            "Speed: 4.6ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 109 at 4.95 sec\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 1 truck, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 110 at 5.00 sec\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 111 at 5.05 sec\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 1 truck, 28.9ms\n",
            "Speed: 4.4ms preprocess, 28.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 112 at 5.09 sec\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 1 truck, 18.6ms\n",
            "Speed: 4.0ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 113 at 5.14 sec\n",
            "\n",
            "0: 384x640 8 cars, 2 buss, 2 trucks, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 114 at 5.18 sec\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 2 trucks, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 115 at 5.23 sec\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 6.6ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 116 at 5.27 sec\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 bus, 2 trucks, 14.1ms\n",
            "Speed: 3.6ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 117 at 5.32 sec\n",
            "\n",
            "0: 384x640 1 person, 9 cars, 1 bus, 2 trucks, 14.2ms\n",
            "Speed: 4.1ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 118 at 5.36 sec\n",
            "\n",
            "0: 384x640 9 cars, 1 bus, 2 trucks, 15.0ms\n",
            "Speed: 3.8ms preprocess, 15.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 119 at 5.41 sec\n",
            "\n",
            "0: 384x640 10 cars, 2 trucks, 14.6ms\n",
            "Speed: 5.9ms preprocess, 14.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 120 at 5.45 sec\n",
            "\n",
            "0: 384x640 13 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 3.4ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 121 at 5.50 sec\n",
            "\n",
            "0: 384x640 11 cars, 2 buss, 1 truck, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 122 at 5.55 sec\n",
            "\n",
            "0: 384x640 11 cars, 2 buss, 2 trucks, 20.3ms\n",
            "Speed: 3.7ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 123 at 5.59 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 2 trucks, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 124 at 5.64 sec\n",
            "\n",
            "0: 384x640 13 cars, 2 buss, 2 trucks, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 125 at 5.68 sec\n",
            "\n",
            "0: 384x640 12 cars, 2 buss, 3 trucks, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 126 at 5.73 sec\n",
            "\n",
            "0: 384x640 11 cars, 2 buss, 2 trucks, 13.8ms\n",
            "Speed: 3.6ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 127 at 5.77 sec\n",
            "\n",
            "0: 384x640 11 cars, 2 buss, 3 trucks, 14.8ms\n",
            "Speed: 6.2ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 128 at 5.82 sec\n",
            "\n",
            "0: 384x640 11 cars, 2 buss, 3 trucks, 13.3ms\n",
            "Speed: 6.1ms preprocess, 13.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 129 at 5.86 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 2 buss, 2 trucks, 14.4ms\n",
            "Speed: 4.6ms preprocess, 14.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 130 at 5.91 sec\n",
            "\n",
            "0: 384x640 10 cars, 2 buss, 2 trucks, 12.1ms\n",
            "Speed: 5.8ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 131 at 5.95 sec\n",
            "\n",
            "0: 384x640 10 cars, 2 buss, 2 trucks, 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 132 at 6.00 sec\n",
            "\n",
            "0: 384x640 9 cars, 2 buss, 2 trucks, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 133 at 6.05 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 2 trucks, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 134 at 6.09 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 8.5ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 135 at 6.14 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 136 at 6.18 sec\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 2 trucks, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 137 at 6.23 sec\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 138 at 6.27 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 139 at 6.32 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 2 trucks, 12.2ms\n",
            "Speed: 4.6ms preprocess, 12.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 140 at 6.36 sec\n",
            "\n",
            "0: 384x640 13 cars, 1 bus, 1 truck, 13.8ms\n",
            "Speed: 4.8ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 141 at 6.41 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 1 truck, 19.1ms\n",
            "Speed: 4.7ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 142 at 6.45 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 1 truck, 21.8ms\n",
            "Speed: 4.5ms preprocess, 21.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 143 at 6.50 sec\n",
            "\n",
            "0: 384x640 9 cars, 1 bus, 1 truck, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 144 at 6.55 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 1 truck, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 145 at 6.59 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 1 truck, 17.4ms\n",
            "Speed: 3.4ms preprocess, 17.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 146 at 6.64 sec\n",
            "\n",
            "0: 384x640 10 cars, 1 bus, 2 trucks, 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 147 at 6.68 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 15.8ms\n",
            "Speed: 4.3ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 148 at 6.73 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 1 truck, 25.7ms\n",
            "Speed: 3.6ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 149 at 6.77 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 2 trucks, 16.6ms\n",
            "Speed: 5.8ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 150 at 6.82 sec\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 2 trucks, 22.0ms\n",
            "Speed: 5.6ms preprocess, 22.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 151 at 6.86 sec\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 1 truck, 14.5ms\n",
            "Speed: 3.6ms preprocess, 14.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 152 at 6.91 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 1 truck, 22.6ms\n",
            "Speed: 3.6ms preprocess, 22.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 153 at 6.95 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 18.8ms\n",
            "Speed: 3.5ms preprocess, 18.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 154 at 7.00 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 155 at 7.05 sec\n",
            "\n",
            "0: 384x640 3 persons, 12 cars, 1 bus, 1 truck, 21.6ms\n",
            "Speed: 3.8ms preprocess, 21.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 156 at 7.09 sec\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 2 trucks, 14.6ms\n",
            "Speed: 4.0ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 157 at 7.14 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 158 at 7.18 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 1 truck, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 159 at 7.23 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 2 trucks, 19.4ms\n",
            "Speed: 3.7ms preprocess, 19.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 160 at 7.27 sec\n",
            "\n",
            "0: 384x640 3 persons, 10 cars, 1 bus, 1 truck, 18.8ms\n",
            "Speed: 4.3ms preprocess, 18.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 161 at 7.32 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 1 truck, 20.0ms\n",
            "Speed: 3.9ms preprocess, 20.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 162 at 7.36 sec\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 4.9ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 163 at 7.41 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 4.7ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 164 at 7.45 sec\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 165 at 7.50 sec\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 4.0ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 166 at 7.55 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 13.8ms\n",
            "Speed: 5.0ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 167 at 7.59 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 5.0ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 168 at 7.64 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 5.4ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 169 at 7.68 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 14.3ms\n",
            "Speed: 6.1ms preprocess, 14.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 170 at 7.73 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 2 trucks, 14.2ms\n",
            "Speed: 3.8ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 171 at 7.77 sec\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 1 truck, 14.2ms\n",
            "Speed: 4.2ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 172 at 7.82 sec\n",
            "\n",
            "0: 384x640 2 persons, 10 cars, 1 bus, 1 truck, 14.1ms\n",
            "Speed: 3.8ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 173 at 7.86 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 truck, 18.5ms\n",
            "Speed: 10.7ms preprocess, 18.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 174 at 7.91 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 4.6ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 175 at 7.95 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 21.5ms\n",
            "Speed: 3.6ms preprocess, 21.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 176 at 8.00 sec\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 1 bus, 2 trucks, 14.9ms\n",
            "Speed: 3.4ms preprocess, 14.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 177 at 8.05 sec\n",
            "\n",
            "0: 384x640 3 persons, 11 cars, 1 bus, 1 truck, 16.7ms\n",
            "Speed: 8.6ms preprocess, 16.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 178 at 8.09 sec\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 1 truck, 13.8ms\n",
            "Speed: 4.2ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 179 at 8.14 sec\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 2 trucks, 14.2ms\n",
            "Speed: 4.1ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 180 at 8.18 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 trucks, 16.4ms\n",
            "Speed: 4.5ms preprocess, 16.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 181 at 8.23 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 13.7ms\n",
            "Speed: 8.6ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 182 at 8.27 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 2 trucks, 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 183 at 8.32 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 4.1ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 184 at 8.36 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 2 trucks, 23.9ms\n",
            "Speed: 4.1ms preprocess, 23.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 185 at 8.41 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 2 trucks, 13.1ms\n",
            "Speed: 5.8ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 186 at 8.45 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 2 trucks, 14.2ms\n",
            "Speed: 5.0ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 187 at 8.50 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 2 trucks, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 188 at 8.55 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 2 trucks, 14.0ms\n",
            "Speed: 4.3ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 189 at 8.59 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 14.1ms\n",
            "Speed: 6.4ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 190 at 8.64 sec\n",
            "\n",
            "0: 384x640 2 persons, 15 cars, 1 bus, 1 truck, 13.9ms\n",
            "Speed: 4.0ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 191 at 8.68 sec\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 1 truck, 13.6ms\n",
            "Speed: 6.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 192 at 8.73 sec\n",
            "\n",
            "0: 384x640 3 persons, 14 cars, 1 bus, 1 truck, 16.8ms\n",
            "Speed: 6.0ms preprocess, 16.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 193 at 8.77 sec\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 1 truck, 14.2ms\n",
            "Speed: 3.9ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing frame 194 at 8.82 sec\n",
            "\n",
            "0: 384x640 2 persons, 13 cars, 1 bus, 2 trucks, 1 traffic light, 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 195 at 8.86 sec\n",
            "\n",
            "0: 384x640 3 persons, 15 cars, 1 bus, 2 trucks, 15.5ms\n",
            "Speed: 3.7ms preprocess, 15.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 196 at 8.91 sec\n",
            "\n",
            "0: 384x640 3 persons, 15 cars, 1 bus, 2 trucks, 18.2ms\n",
            "Speed: 3.7ms preprocess, 18.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 197 at 8.95 sec\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 3 trucks, 13.8ms\n",
            "Speed: 4.0ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 198 at 9.00 sec\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 3 trucks, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 199 at 9.05 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 2 buss, 2 trucks, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 200 at 9.09 sec\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 2 buss, 2 trucks, 18.6ms\n",
            "Speed: 6.6ms preprocess, 18.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 201 at 9.14 sec\n",
            "\n",
            "0: 384x640 3 persons, 13 cars, 1 bus, 2 trucks, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 202 at 9.18 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 3 trucks, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 203 at 9.23 sec\n",
            "\n",
            "0: 384x640 2 persons, 12 cars, 1 bus, 3 trucks, 14.3ms\n",
            "Speed: 5.8ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 204 at 9.27 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 2 buss, 3 trucks, 13.9ms\n",
            "Speed: 5.7ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 205 at 9.32 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 2 buss, 1 truck, 19.4ms\n",
            "Speed: 3.9ms preprocess, 19.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 206 at 9.36 sec\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 2 buss, 1 truck, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 207 at 9.41 sec\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 2 buss, 1 truck, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 208 at 9.45 sec\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 2 buss, 1 truck, 14.2ms\n",
            "Speed: 4.9ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 209 at 9.50 sec\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 2 buss, 1 truck, 14.1ms\n",
            "Speed: 3.2ms preprocess, 14.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 210 at 9.55 sec\n",
            "\n",
            "0: 384x640 2 persons, 18 cars, 2 buss, 1 truck, 23.7ms\n",
            "Speed: 3.5ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 211 at 9.59 sec\n",
            "\n",
            "0: 384x640 2 persons, 16 cars, 1 bus, 2 trucks, 1 traffic light, 19.0ms\n",
            "Speed: 3.9ms preprocess, 19.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 212 at 9.64 sec\n",
            "\n",
            "0: 384x640 1 person, 16 cars, 2 buss, 1 truck, 1 traffic light, 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 213 at 9.68 sec\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 2 buss, 2 trucks, 1 traffic light, 18.0ms\n",
            "Speed: 3.4ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 214 at 9.73 sec\n",
            "\n",
            "0: 384x640 2 persons, 17 cars, 1 bus, 2 trucks, 1 traffic light, 16.4ms\n",
            "Speed: 3.6ms preprocess, 16.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 215 at 9.77 sec\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 2 buss, 1 truck, 21.0ms\n",
            "Speed: 3.5ms preprocess, 21.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 216 at 9.82 sec\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 2 buss, 1 truck, 14.3ms\n",
            "Speed: 3.8ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 217 at 9.86 sec\n",
            "\n",
            "0: 384x640 1 person, 18 cars, 1 bus, 1 truck, 18.0ms\n",
            "Speed: 3.7ms preprocess, 18.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 218 at 9.91 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 219 at 9.95 sec\n",
            "\n",
            "0: 384x640 1 person, 17 cars, 1 bus, 1 truck, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 220 at 10.00 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 16.5ms\n",
            "Speed: 3.3ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 221 at 10.05 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 20.2ms\n",
            "Speed: 3.4ms preprocess, 20.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 222 at 10.09 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 223 at 10.14 sec\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 truck, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 224 at 10.18 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 13.9ms\n",
            "Speed: 4.2ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 225 at 10.23 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 bus, 13.4ms\n",
            "Speed: 4.0ms preprocess, 13.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 226 at 10.27 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 bus, 14.1ms\n",
            "Speed: 4.1ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 227 at 10.32 sec\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 228 at 10.36 sec\n",
            "\n",
            "0: 384x640 17 cars, 1 bus, 14.0ms\n",
            "Speed: 4.2ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 229 at 10.41 sec\n",
            "\n",
            "0: 384x640 15 cars, 13.6ms\n",
            "Speed: 4.0ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 230 at 10.45 sec\n",
            "\n",
            "0: 384x640 14 cars, 13.9ms\n",
            "Speed: 5.2ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 231 at 10.50 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 14.2ms\n",
            "Speed: 3.7ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 232 at 10.55 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 traffic light, 14.0ms\n",
            "Speed: 5.5ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 233 at 10.59 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 traffic light, 13.8ms\n",
            "Speed: 3.4ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 234 at 10.64 sec\n",
            "\n",
            "0: 384x640 1 person, 15 cars, 1 traffic light, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 235 at 10.68 sec\n",
            "\n",
            "0: 384x640 1 person, 13 cars, 1 truck, 18.6ms\n",
            "Speed: 3.6ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 236 at 10.73 sec\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 16.2ms\n",
            "Speed: 3.4ms preprocess, 16.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 237 at 10.77 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 14.2ms\n",
            "Speed: 6.7ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 238 at 10.82 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 12.4ms\n",
            "Speed: 5.9ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 239 at 10.86 sec\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 1 truck, 13.9ms\n",
            "Speed: 3.4ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 240 at 10.91 sec\n",
            "\n",
            "0: 384x640 1 person, 10 cars, 1 bus, 14.1ms\n",
            "Speed: 3.7ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 241 at 10.95 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 16.4ms\n",
            "Speed: 3.5ms preprocess, 16.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 242 at 11.00 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 13.9ms\n",
            "Speed: 6.0ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 243 at 11.05 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 244 at 11.09 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 13.8ms\n",
            "Speed: 6.2ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 245 at 11.14 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 14.3ms\n",
            "Speed: 4.1ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 246 at 11.18 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 14.5ms\n",
            "Speed: 4.6ms preprocess, 14.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 247 at 11.23 sec\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 1 truck, 14.7ms\n",
            "Speed: 4.5ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 248 at 11.27 sec\n",
            "\n",
            "0: 384x640 2 persons, 14 cars, 1 bus, 1 truck, 14.4ms\n",
            "Speed: 4.8ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 249 at 11.32 sec\n",
            "\n",
            "0: 384x640 1 person, 14 cars, 1 bus, 23.4ms\n",
            "Speed: 15.4ms preprocess, 23.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 250 at 11.36 sec\n",
            "\n",
            "0: 384x640 1 person, 12 cars, 1 bus, 13.7ms\n",
            "Speed: 4.2ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 251 at 11.41 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 1 truck, 12.2ms\n",
            "Speed: 3.9ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 252 at 11.45 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 1 truck, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 253 at 11.50 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 14.1ms\n",
            "Speed: 5.2ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 254 at 11.55 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 14.3ms\n",
            "Speed: 3.6ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 255 at 11.59 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 256 at 11.64 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 12.8ms\n",
            "Speed: 5.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 257 at 11.68 sec\n",
            "\n",
            "0: 384x640 1 person, 11 cars, 1 bus, 1 truck, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 258 at 11.73 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 259 at 11.77 sec\n",
            "\n",
            "0: 384x640 2 persons, 11 cars, 1 bus, 14.0ms\n",
            "Speed: 4.1ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 260 at 11.82 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 13.7ms\n",
            "Speed: 3.9ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 261 at 11.86 sec\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 15.7ms\n",
            "Speed: 3.7ms preprocess, 15.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 262 at 11.91 sec\n",
            "\n",
            "0: 384x640 12 cars, 1 bus, 15.4ms\n",
            "Speed: 3.9ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing frame 263 at 11.95 sec\n",
            "\n",
            "0: 384x640 11 cars, 1 bus, 1 truck, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video processing complete!\n",
            "Processing complete! Video saved at: /content/drive/My Drive/deepdrive/detected_output.avi\n",
            "Moviepy - Building video /content/drive/My Drive/deepdrive/final_output.mp4.\n",
            "MoviePy - Writing audio in final_outputTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/drive/My Drive/deepdrive/final_output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/My Drive/deepdrive/final_output.mp4\n",
            "Final video with audio saved at: /content/drive/My Drive/deepdrive/final_output.mp4\n"
          ]
        }
      ]
    }
  ]
}